{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import scale\n",
    "import json\n",
    "from sensible_raw.loaders import loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Part 1. Build dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from build_dataset.extractors.sms_extractor import Sms_extractor\n",
    "from build_dataset.extractors.bandicoot_extractor import Bandicoot_extractor\n",
    "from build_dataset.extractors.stop_locations_extractor import Stop_locations_extractor\n",
    "from build_dataset.extractors.screen_extractor import Screen_extractor\n",
    "##from facebook_friends_extractor import Facebook_friends_extractor\n",
    "from build_dataset.extractors.bluetooth_extractor import Bluetooth_extractor\n",
    "##from calllog_extractor import Calllog_extractor\n",
    "##from location_extractor import Location_extractor\n",
    "from build_dataset.extractors.big_five_extractor import Big_five_extractor\n",
    "\n",
    "from build_dataset.analysis.outlier_detection import Outlier_detector_svm, Outlier_detector_kd\n",
    "from build_dataset.analysis.location_reference import Load_location_reference\n",
    "#from analysis.social_state_reference import Load_social_state_reference\n",
    "from build_dataset.analysis.consensus_archetypes import Consensus_archetypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tc0: School periods (when there are lectures)\n",
    "# tc1: Exam periods\n",
    "# tc2: Holiday periods\n",
    "\n",
    "tc0 = {'hours': range(24), 'days': range(7), 'spans': [(\"06/01/14\",\"24/01/14\"), (\"03/02/14\",\"16/05/14\"), (\"01/09/14\",\"05/12/14\"), (\"02/06/14\",\"20/06/14\")]}\n",
    "tc1 = {'hours': range(24), 'days': range(7), 'spans': [(\"17/05/14\",\"01/06/14\"), (\"06/12/14\", \"21/12/14\")]}\n",
    "tc2 = {'hours': range(24), 'days': range(7), 'spans': [(\"01/01/14\",\"05/01/14\"), (\"25/01/14\",\"02/02/14\"), (\"14/04/14\",\"20/04/14\"), (\"21/06/14\",\"30/08/14\"), (\"22/12/14\", \"31/12/14\")]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[location_reference] Loading datasource from local.\n"
     ]
    }
   ],
   "source": [
    "location_reference = Load_location_reference(tc0, auxlabel=\"tc0_\", load_reference=True)\n",
    "#social_state_reference = Load_social_state_reference(tc0, auxlabel=\"tc0_\", load_reference=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sms] Loading datasource from local.\n",
      "[sms] Number of datapoints in range: 1786225\n",
      "[stop_locations] Loading datasource from local.\n",
      "[stop_locations] Number of datapoints in range: 450662\n",
      "[screen] Loading datasource from local.\n",
      "[screen] Number of datapoints in range: 20211170\n",
      "[bluetooth] Loading datasource from local.\n",
      "[bluetooth] Number of datapoints in range: 3312659\n",
      "[big_five_extractor] Loaded data from local copy!\n"
     ]
    }
   ],
   "source": [
    "load_datasources_from_local = True\n",
    "\n",
    "sms = Sms_extractor(tc0, suppress=[], auxlabel=\"tc0_\", load_old_datasources=load_datasources_from_local)\n",
    "bandicoot = Bandicoot_extractor(tc0, supress=[], auxlabel=\"tc0_\", load_old_datasources=load_datasources_from_local)\n",
    "stop_locations = Stop_locations_extractor(tc0, suppress=[], auxlabel=\"tc0_\", load_old_datasources=load_datasources_from_local)\n",
    "screen = Screen_extractor(tc0, suppress=[], auxlabel=\"tc0_\", load_old_datasources=load_datasources_from_local)\n",
    "##facebook_friends = Facebook_friends_extractor()\n",
    "bluetooth = Bluetooth_extractor(tc0, suppress=[], auxlabel=\"tc0_\", load_old_datasources=load_datasources_from_local)\n",
    "##calllog = Calllog_extractor()\n",
    "##location = Location_extractor()\n",
    "big_five = Big_five_extractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#tc0 = {'hours': range(24), 'days': range(7), 'spans': [(\"06/01/14\",\"24/01/14\"), (\"03/02/14\",\"16/05/14\"), (\"01/09/14\",\"05/12/14\"), (\"02/06/14\",\"20/06/14\")]} #in school\n",
    "#location_reference = Load_location_reference(tc1, auxlabel=\"tc1_\", load_reference=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build full JSON dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def build_json_dataset(load_cached_data_sets=True):\n",
    "    \"\"\"Build json dataset with key for every user\n",
    "    \n",
    "    Loop over user-ids and for each one, collect features from the\n",
    "    extractors. That's basically it.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    load_cached_data_sets : bool\n",
    "        Option to load prebuilt json datasets and just return those\n",
    "        or to build them from scratch again. Note that building from\n",
    "    \"\"\"\n",
    "    \n",
    "    # Collect a list of valid user-ids\n",
    "    with open('build_dataset/data_cache/users.json', 'r') as infile:\n",
    "        users = [int(i) for i in json.load(infile)]\n",
    "\n",
    "    if load_cached_data_sets:\n",
    "        with open('build_dataset/data_cache/dataset_X.json') as infile:\n",
    "            dataset_X = json.load(infile)\n",
    "        with open('build_dataset/data_cache/dataset_Y.json') as infile:\n",
    "            dataset_Y = json.load(infile)\n",
    "    else:\n",
    "        dataset_X = {}\n",
    "        dataset_Y = {}\n",
    "\n",
    "        for user in users:\n",
    "\n",
    "            if user%10 == 0:\n",
    "                print user,\n",
    "\n",
    "            datapoint_x = {}\n",
    "            datapoint_y = {}\n",
    "\n",
    "            # Ordered by fail/execution speed\n",
    "            try:\n",
    "                datapoint_x.update(bluetooth.main(user))\n",
    "                datapoint_x.update(stop_locations.main(user))\n",
    "                datapoint_x.update(sms.main(user))\n",
    "                datapoint_x.update(screen.main(user))\n",
    "                #datapoint_x.update(facebook_friends.main(user))\n",
    "                #datapoint_x.update(calllog.main(user))\n",
    "                #datapoint_x.update(location.main(user))\n",
    "                datapoint_y.update(big_five.main(user))\n",
    "            except Exception as e:\n",
    "                print \"<\"+str(e)+\">\",\n",
    "                continue\n",
    "\n",
    "            dataset_X[user] = datapoint_x\n",
    "            dataset_Y[user] = datapoint_y\n",
    "\n",
    "        # Store loaded data    \n",
    "        with open('build_dataset/data_cache/dataset_X.json', 'w') as outfile:\n",
    "            json.dump(dataset_X,outfile)\n",
    "        with open('build_dataset/data_cache/dataset_Y.json', 'w') as outfile:\n",
    "            json.dump(dataset_Y,outfile)\n",
    "    \n",
    "    return dataset_X, dataset_Y\n",
    "\n",
    "\n",
    "dataset_X, dataset_Y = build_json_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to matrix and standardize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features_x = sorted(dataset_X.items()[0][1].keys())\n",
    "features_y = ['openness', 'conscientiousness', 'extraversion', 'aggreeableness', 'neuroticism']\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "for k,v in dataset_X.items():\n",
    "    X.append([v[f] for f in features_x])\n",
    "for k,v in dataset_Y.items():\n",
    "    Y.append([v[f] for f in features_y])\n",
    "    \n",
    "X_scaled = scale(np.array(X))\n",
    "Y = np.array(Y)\n",
    "M = Consensus_archetypes().project_to_archetype_space(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: u'tc0_bluetooth_social_entropy',\n",
       " 1: u'tc0_screen_session_duration',\n",
       " 2: u'tc0_screen_session_frequency',\n",
       " 3: u'tc0_screen_summed_usage',\n",
       " 4: u'tc0_sms_fractions_of_conversations_started',\n",
       " 5: u'tc0_sms_overall_received_responsiveness',\n",
       " 6: u'tc0_sms_overall_responsiveness',\n",
       " 7: u'tc0_sms_selectivity_in_responsiveness',\n",
       " 8: u'tc0_sms_traffic',\n",
       " 9: u'tc0_stop_locations_geospacial_entropy'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature reference \n",
    "dict(zip(range(len(features_x)),features_x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 50 outliers, clean subset has 577 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ulf/anaconda2/lib/python2.7/site-packages/numpy/lib/function_base.py:3875: FutureWarning: in the future negative indices will not be ignored by `numpy.delete`.\n",
      "  \"`numpy.delete`.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#out_svm = Outlier_detector_svm(X_scaled[:,[5,7]], hard=False, threshold=-1, visualize=False, nu=0.1, gamma=0.25)\n",
    "out_kd = Outlier_detector_kd(X_scaled, visualize=False, threshold=0.08, bandwidth=2, kernel='gaussian')\n",
    "outliers = out_kd.main()\n",
    "\n",
    "X_clean = np.delete(X_scaled,outliers,axis=0)\n",
    "Y_clean = np.delete(Y,outliers,axis=0)\n",
    "M_clean = np.delete(M,outliers,axis=0)\n",
    "\n",
    "print \"Removed %d outliers, clean subset has %d samples\" % (\n",
    "    (X_scaled.shape[0]-X_clean.shape[0]), X_clean.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.savetxt(\"data/X.csv\", X, delimiter=\",\")\n",
    "np.savetxt(\"data/X_scaled.csv\", X_scaled, delimiter=\",\")\n",
    "np.savetxt(\"data/Y.csv\", Y, delimiter=\",\")\n",
    "np.savetxt(\"data/X_clean.csv\", X_clean, delimiter=\",\")\n",
    "np.savetxt(\"data/Y_clean.csv\", Y_clean, delimiter=\",\")\n",
    "np.savetxt(\"data/M.csv\", M, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2. Pareto clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "from pareto_clustering.cluster.build_S import Build_S\n",
    "from pareto_clustering.cluster import cluster_Infomap\n",
    "from pareto_clustering.cluster import cluster_DBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#X = np.loadtxt(\"data/X.csv\", delimiter=\",\")\n",
    "#X_scaled = np.loadtxt(\"data/X_scaled.csv\", delimiter=\",\")\n",
    "#Y = np.loadtxt(\"data/Y.csv\", delimiter=\",\")\n",
    "#X_clean = np.loadtxt(\"data/X_clean.csv\", delimiter=\",\")\n",
    "#Y_clean = np.loadtxt(\"data/Y_clean.csv\", delimiter=\",\")\n",
    "#M = np.loadtxt(\"data/M.csv\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_scaled = np.loadtxt(\"data/X_users_mean.csv\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pareto clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0% 8/703\n",
      "10% 78/703\n",
      "20% 148/703\n",
      "30% 218/703\n",
      "40% 289/703\n",
      "50% 359/703\n",
      "Failed for: origz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pareto_clustering/dependencies/point_location/geo/shapes.py:96: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return numerator / denominator\n"
     ]
    },
    {
     "ename": "TimeoutException",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTimeoutException\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-98f828f6ebe7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBuild_S\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_scaled\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msample_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremove_outliers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvisualize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mclusters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcluster_Infomap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mclusters_dbscan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcluster_DBSCAN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ulfaslak/Dropbox/school/sem12/MScProject/Academic/code/pipeline_code/pareto_clustering/cluster/build_S.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(self, visualize)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisualize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m                 \u001b[0mP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpair_triangles_orig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpair_inliers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpair_outliers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_S\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvisualize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvisualize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mvisualize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_show_triangle_plots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpair_triangles_orig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpair_inliers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpair_outliers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ulfaslak/Dropbox/school/sem12/MScProject/Academic/code/pipeline_code/pareto_clustering/cluster/build_S.py\u001b[0m in \u001b[0;36m_build_S\u001b[0;34m(self, visualize)\u001b[0m\n\u001b[1;32m    204\u001b[0m                                         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m                                                 \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Failed for: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mfailed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m                                                 \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m                                                 \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Distribution of points for which mintri calc fails\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m                                                 \u001b[0;32mif\u001b[0m \u001b[0mfailed\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"orig\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ulfaslak/miniconda/lib/python2.7/site-packages/matplotlib/pyplot.pyc\u001b[0m in \u001b[0;36mfigure\u001b[0;34m(num, figsize, dpi, facecolor, edgecolor, frameon, FigureClass, **kwargs)\u001b[0m\n\u001b[1;32m    525\u001b[0m                                         \u001b[0mframeon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mframeon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m                                         \u001b[0mFigureClass\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFigureClass\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 527\u001b[0;31m                                         **kwargs)\n\u001b[0m\u001b[1;32m    528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfigLabel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ulfaslak/miniconda/lib/python2.7/site-packages/matplotlib/backends/backend_agg.pyc\u001b[0m in \u001b[0;36mnew_figure_manager\u001b[0;34m(num, *args, **kwargs)\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[0mFigureClass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'FigureClass'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFigure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m     \u001b[0mthisFig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFigureClass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_figure_manager_given_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthisFig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ulfaslak/miniconda/lib/python2.7/site-packages/matplotlib/figure.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, figsize, dpi, facecolor, edgecolor, linewidth, frameon, subplotpars, tight_layout)\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdpi_scale_trans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAffine2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdpi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdpi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbbox_inches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_bounds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbbox\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTransformedBbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbbox_inches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdpi_scale_trans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ulfaslak/miniconda/lib/python2.7/site-packages/matplotlib/figure.pyc\u001b[0m in \u001b[0;36m_set_dpi\u001b[0;34m(self, dpi)\u001b[0m\n\u001b[1;32m    408\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set_dpi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dpi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdpi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdpi_scale_trans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdpi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    411\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dpi_changed'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m     \u001b[0mdpi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproperty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_get_dpi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_set_dpi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ulfaslak/miniconda/lib/python2.7/site-packages/matplotlib/transforms.pyc\u001b[0m in \u001b[0;36mscale\u001b[0;34m(self, sx, sy)\u001b[0m\n\u001b[1;32m   1964\u001b[0m             \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1965\u001b[0m             np.float_)\n\u001b[0;32m-> 1966\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mtx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscale_mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mtx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1967\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1968\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ulfaslak/Dropbox/school/sem12/MScProject/Academic/code/pipeline_code/pareto_clustering/cluster/build_S.py\u001b[0m in \u001b[0;36mtimeout_handler\u001b[0;34m(signum, frame)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtimeout_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m   \u001b[0;31m# Custom signal handler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutException\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mBuild_S\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTimeoutException\u001b[0m: "
     ]
    }
   ],
   "source": [
    "_, T, _ = Build_S(X_scaled,10,sample_size=1.0, remove_outliers=True).main(visualize=False)\n",
    "clusters = cluster_Infomap.fit(T)\n",
    "clusters_dbscan = cluster_DBSCAN.fit(T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create datasets for each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_all = []\n",
    "for clu, traits in clusters.items():\n",
    "    Xc = X_clean[:,np.array(traits)-1]\n",
    "    X_all.append(Xc)\n",
    "    \n",
    "for i, Xc in enumerate(X_all):\n",
    "    np.savetxt(\"data/X%s.csv\" % i, Xc, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  <br>\n",
    "  <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
