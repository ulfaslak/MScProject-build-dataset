{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime as dt\n",
    "from collections import defaultdict\n",
    "%matplotlib inline\n",
    "import matplotlib.pylab as plt\n",
    "import os\n",
    "from sklearn.preprocessing import scale\n",
    "import bandicoot_dev as bc_d\n",
    "from build_dataset.workers import load_sensible_data as lsd\n",
    "from build_dataset.analysis import location_reference as locref\n",
    "from build_dataset.analysis import timezone_reference as tzref\n",
    "#from build_dataset.workers import apply_timezone_offset as ato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tc0 = {\n",
    "    'hours': range(24),\n",
    "    'days': range(7),\n",
    "    'spans': [\n",
    "        (\"06/01/14\", \"24/01/14\"),\n",
    "        (\"03/02/14\", \"16/05/14\"),\n",
    "        (\"01/09/14\", \"05/12/14\"),\n",
    "        (\"02/06/14\", \"20/06/14\")\n",
    "    ]\n",
    "}\n",
    "tc1 = {\n",
    "    'hours': range(24),\n",
    "    'days': range(7),\n",
    "    'spans': [\n",
    "        (\"17/05/14\", \"01/06/14\"),\n",
    "        (\"06/12/14\", \"21/12/14\")\n",
    "    ]\n",
    "}\n",
    "tc2 = {\n",
    "    'hours': range(24),\n",
    "    'days': range(7),\n",
    "    'spans': [\n",
    "        (\"01/01/14\", \"05/01/14\"),\n",
    "        (\"25/01/14\", \"02/02/14\"),\n",
    "        (\"14/04/14\", \"20/04/14\"),\n",
    "        (\"21/06/14\", \"30/08/14\"),\n",
    "        (\"22/12/14\", \"31/12/14\")\n",
    "    ]\n",
    "}\n",
    "tc3 = {\n",
    "    'hours': range(24),\n",
    "    'days': range(7),\n",
    "    'spans': [\n",
    "        (\"01/01/14\", \"31/12/14\")\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "location_reference_tc0 = locref.Load_location_reference(tc0).location_reference\n",
    "location_reference_tc1 = locref.Load_location_reference(tc1).location_reference\n",
    "location_reference_tc2 = locref.Load_location_reference(tc2).location_reference\n",
    "location_reference_tc3 = locref.Load_location_reference(tc3).location_reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_call = lsd.load(tc0, \"calllog\")\n",
    "df_sms = lsd.load(tc0, \"sms\")\n",
    "#df_screen = ato.apply(lsd.load(tc0, \"screen\"), tc0)\n",
    "#df_stop_locations = lsd.load(tc0, \"stop_locations\")\n",
    "#df_bt = ato.apply(lsd.load(tc0, \"bluetooth\", filtering=\"bt_special\"), tc0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "users = set(list(df_call['user'])) & set(list(df_sms['user']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 10 20 30 40 50 60 70 80 90 100 110 120 130 140 150 160 170 180 190 200 210 220 230 240 250 260 270 280 290 300 310 320 330 340 350 360 370 380 390 400 410 420 430 440 450 460 470 480 490 500 510 520 530 550 560 570 580 590 600 610 620 630 640 660 670 680 690 700 710 720 730 760 780 790 800 810 820 830 840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python2/lib/python2.7/site-packages/ipykernel/__main__.py:79: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n"
     ]
    }
   ],
   "source": [
    "def _filter_call(df_u):\n",
    "    df_u = df_u.drop('user', 1)\n",
    "    df_u['interaction'] = \"call\"\n",
    "    df_u['timestamp'] = [dt.fromtimestamp(t) for t in df_u['timestamp']]\n",
    "    df_u['type'] = [\"in\" if t == 1 else \"out\" for t in df_u['type']]\n",
    "    df_u.columns = [\"duration\", \"correspondent_id\", \"datetime\", \"direction\", \"interaction\"]\n",
    "    return df_u\n",
    "\n",
    "def _filter_sms(df_u):\n",
    "    df_u = df_u[df_u['status'] <= 0]\n",
    "    df_u = df_u[df_u['type'] <= 2]\n",
    "    df_u = df_u.drop(['status','user'], 1)\n",
    "    df_u['interaction'] = 'text'\n",
    "    df_u['timestamp'] = [dt.fromtimestamp(t) for t in df_u['timestamp']]\n",
    "    df_u['type'] = [\"in\" if t == 1 else \"out\" for t in df_u['type']]\n",
    "    df_u['duration'] = ''\n",
    "    df_u.columns = [\"correspondent_id\", \"datetime\", \"direction\", \"interaction\", \"duration\"]\n",
    "    return df_u\n",
    "\n",
    "def _filter_physical(u, df_u):\n",
    "    df_u['interaction'] = 'physical'\n",
    "    df_u['direction'] = ''\n",
    "    df_u['timestamp'] = [dt.fromtimestamp(t) for t in df_u['timestamp']]\n",
    "    df_u['correspondent_id'] = [a if a != u else b \n",
    "                                for a,b in zip(df_u['bt_mac'].values, df_u['user'].values)]\n",
    "    df_u['duration'] = \"\"\n",
    "    df_u = df_u.drop(['class','id','bt_mac','rssi', 'user'], 1)\n",
    "    df_u.columns = [\"datetime\", \"interaction\", \"direction\", \"correspondent_id\", \"duration\"]\n",
    "    return df_u\n",
    "\n",
    "def _filter_screen(df_u):\n",
    "    sessions = []\n",
    "    i = 0\n",
    "    for row in df_u.iterrows():\n",
    "        event, times = row[1]['screen_on'], row[1]['timestamp']\n",
    "        if i == 0:\n",
    "            prev_event = event\n",
    "            prev_times = times\n",
    "            i+=1; continue\n",
    "        elif event == 0 and prev_event == 1:\n",
    "            duration = (times-prev_times)/1000\n",
    "            sessions.append({'datetime': dt.fromtimestamp(prev_times/1000), \n",
    "                             'duration': duration})\n",
    "        prev_event = event\n",
    "        prev_times = times\n",
    "        i+=1\n",
    "    df_u = pd.DataFrame(sessions)\n",
    "    df_u['interaction'] = 'screen'\n",
    "    return df_u\n",
    "\n",
    "def _filter_stop_locations(u, df_u):\n",
    "    def evaluate_event(r):\n",
    "        user, label, arrival, departure = \\\n",
    "        r[1]['user'], r[1]['label'], r[1]['arrival'], r[1]['departure']\n",
    "        \n",
    "        state = location_reference_tc0[str(user)]['%.1f'%label]\n",
    "        if state['type'] == \"home\":\n",
    "            return \"home\"\n",
    "        if state['type'] == \"campus\":\n",
    "            if state['__friday_bar'] and dt.fromtimestamp(np.mean([arrival,departure])).hour >=17:\n",
    "                return \"friday_bar\"\n",
    "            return \"campus\"\n",
    "        return \"other\"\n",
    "        \n",
    "    df_u['duration'] = df_u['departure'] - df_u['arrival']\n",
    "    df_u['datetime'] = [dt.fromtimestamp(t) for t in df_u['arrival']]\n",
    "    df_u['position'] = [\"%d_%s\" % (u, l) for l in df_u['label']]\n",
    "    df_u['event'] = [evaluate_event(r) for r in df_u.iterrows()]\n",
    "    df_u = df_u.drop(['arrival', 'departure', 'label', 'lat', 'lon', 'timestamp', 'user'], 1)\n",
    "    return df_u\n",
    "    \n",
    "\n",
    "for u in users:\n",
    "    df_call_u = _filter_call(df_call[df_call['user'] == u])\n",
    "    df_sms_u = _filter_sms(df_sms[df_sms['user'] == u])\n",
    "    #df_physical_u = _filter_physical(u, df_physical[(df_physical['user'] == u) | (df_physical['bt_mac'] == u)])\n",
    "    #df_screen_u = _filter_screen(df_screen[df_screen['user'] == u])\n",
    "    #df_stop_locations_u = _filter_stop_locations(u, df_stop_locations[df_stop_locations['user'] == u])\n",
    "    \n",
    "    df_cellular = pd.concat([df_sms_u, df_call_u]).sort(['datetime'], ascending=1)\n",
    "    df_cellular.to_csv(\"../data_cache/records/cellular/%d.csv\" % u, \n",
    "                          index=False)\n",
    "    #df_physical.to_csv(\"physical/%d.csv\" % u, index=False)\n",
    "    #df_screen.to_csv(\"screen/%d.csv\" % u, index=False)\n",
    "    #df_stop_locations.to_csv(ROOTPATH + \\\n",
    "    #                         \"build_dataset/data_cache/records/stop_locations/%d.csv\" % u, \n",
    "    #                         index=False)\n",
    "    \n",
    "    if u%10==0:\n",
    "        print u,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_features(userid, groupby=\"week\", summary=\"special\"):\n",
    "    \n",
    "    user = bc_d.read_csv(\"%d\" % userid, \n",
    "                         \"../data_cache/records/cellular/\", \n",
    "                         network=False,\n",
    "                         describe=False)\n",
    "    \n",
    "    indicators = bc_d.utils.all(user, \n",
    "                                groupby=groupby, \n",
    "                                summary=summary, \n",
    "                                dist=True, \n",
    "                                network=True, \n",
    "                                spatial=False)\n",
    "    \n",
    "    for ex in ['name', 'reporting']:\n",
    "        del indicators[ex]\n",
    "        \n",
    "    return bc_d.utils.flatten(indicators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWarning: No data provided!\u001b[0m\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'bad_records' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-80-db0a2dd0b361>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0muser\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0musers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muser\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m# Initiate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-79-9c7b128ac598>\u001b[0m in \u001b[0;36mcompute_features\u001b[1;34m(userid, groupby, summary)\u001b[0m\n\u001b[0;32m      4\u001b[0m                          \u001b[1;34m\"../data_cache/records/cellular/\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                          \u001b[0mnetwork\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m                          describe=True)\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     indicators = bc_d.utils.all(user, \n",
      "\u001b[1;32m/home/ulfaslak@gmail.com/backup/pipeline_code/bandicoot_dev/io.pyc\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(user_id, records_path, physical_path, screen_path, stop_locations_path, attributes_path, network, describe, warnings, errors)\u001b[0m\n\u001b[0;32m    415\u001b[0m                              \u001b[0mphysical\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstop_locations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattributes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    416\u001b[0m                              \u001b[0mattributes_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattributes_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdescribe\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 417\u001b[1;33m                              warnings=warnings)\n\u001b[0m\u001b[0;32m    418\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    419\u001b[0m     \u001b[1;31m# Loads the network\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ulfaslak@gmail.com/backup/pipeline_code/bandicoot_dev/io.pyc\u001b[0m in \u001b[0;36mload\u001b[1;34m(name, records, physical, screen, stop_locations, attributes, attributes_path, describe, warnings)\u001b[0m\n\u001b[0;32m    286\u001b[0m         \u001b[0muser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 288\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0muser\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbad_records\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    289\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'bad_records' referenced before assignment"
     ]
    }
   ],
   "source": [
    "for user in sorted(users):\n",
    "    \n",
    "    ds = compute_features(user)\n",
    "    \n",
    "    # Initiate\n",
    "    if int(user) == 0:\n",
    "        feat_names = []\n",
    "        M = len(ds) + sum([1 for v in ds.values() if type(v[0]) is dict])\n",
    "        N = len(ds.values()[0])\n",
    "        all_X = [np.empty((0,M))] * N\n",
    "    \n",
    "    # Extract features for user in matrix format. The matrix feat_vects has\n",
    "    # a row vector of feature values for each week.\n",
    "    feat_vects = np.ones((N,M))\n",
    "    \n",
    "    c = 0\n",
    "    for j, (f, vals) in enumerate(ds.items()):\n",
    "        \n",
    "        if user == 0:\n",
    "            if type(vals[0]) is dict:\n",
    "                feat_names.append(f+\"_mean\")\n",
    "                feat_names.append(f+\"_std\")\n",
    "            else:\n",
    "                feat_names.append(f)\n",
    "            \n",
    "        for i, v in enumerate(vals):\n",
    "            if type(v) is dict:\n",
    "                feat_vects[i,j+c] = v['mean']\n",
    "                feat_vects[i,j+c+1] = v['std']\n",
    "                if i == 0: c += 1\n",
    "            else:\n",
    "                feat_vects[i, j+c] = v\n",
    "        \n",
    "    for i in range(N):\n",
    "        all_X[i] = np.append(all_X[i], [feat_vects[i, :]], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_X_clean = [X[:,~np.isnan(X).any(0)] for X in all_X]\n",
    "all_X_scaled = [scale(X) for X in all_X_clean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(762, 33)\n",
      "(762, 34)\n",
      "(762, 34)\n",
      "(762, 34)\n",
      "(762, 34)\n",
      "(762, 34)\n",
      "(762, 34)\n",
      "(762, 34)\n",
      "(762, 34)\n",
      "(762, 34)\n",
      "(762, 34)\n",
      "(762, 34)\n",
      "(762, 34)\n",
      "(762, 34)\n",
      "(762, 34)\n",
      "(762, 34)\n",
      "(762, 34)\n",
      "(762, 34)\n",
      "(762, 34)\n",
      "(762, 34)\n",
      "(762, 34)\n",
      "(762, 34)\n",
      "(762, 34)\n",
      "(762, 34)\n",
      "(762, 34)\n",
      "(762, 34)\n",
      "(762, 34)\n",
      "(762, 34)\n",
      "(762, 34)\n",
      "(762, 34)\n",
      "(762, 34)\n",
      "(762, 34)\n",
      "(762, 34)\n",
      "(762, 34)\n",
      "(762, 34)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(all_X)):\n",
    "    print all_X_clean[i].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 9 25 34 54 68 93 101 108 110 132 141 154 179 196 198 246 309 325 410 421 427 431 445 446 471 492 507 522 526 587 596 613 618 622 636 639 658 669 675 683 696 705 711 712 713 724 754 761 \n",
      "\n",
      "response_delay_text__allweek__allday__callandtext_mean\n",
      "response_delay_text__allweek__allday__callandtext_std\n"
     ]
    }
   ],
   "source": [
    "for i in range(all_X[0].shape[0]):\n",
    "    if np.isnan(all_X[0][i, :]).any():\n",
    "        print i,\n",
    "        \n",
    "print \"\\n\"\n",
    "        \n",
    "for j in range(all_X[0].shape[1]):\n",
    "    if np.isnan(all_X[0][:, j]).any():\n",
    "        print feat_names[j]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert all_X to a 3D-array instead of a list of arrays, and interpolate nans across weeks of participants (y direction), not across attribute values of participants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for j in range(all_X[3].shape[1]):\n",
    "    mask_j = np.isnan(all_X[3][:,j])\n",
    "    all_X[3][mask_j,j] = np.interp(np.flatnonzero(mask_j), np.flatnonzero(~mask_j), all_X[3][~mask_j,j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def interpolate_nans(X):\n",
    "    \"\"\"Overwrite NaNs with column value interpolations.\"\"\"\n",
    "    for j in range(X.shape[1]):\n",
    "        mask_j = np.isnan(X[:,j])\n",
    "        X[mask_j,j] = np.interp(np.flatnonzero(mask_j), np.flatnonzero(~mask_j), X[~mask_j,j])\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_incomplete = np.array([[10,     20,     30    ],\n",
    "                         [np.nan, 30,     np.nan],\n",
    "                         [np.nan, np.nan, 50    ],\n",
    "                         [40,     50,     np.nan    ]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 10.  20.  30.]\n",
      " [ 20.  30.  40.]\n",
      " [ 30.  40.  50.]\n",
      " [ 40.  50.  50.]]\n"
     ]
    }
   ],
   "source": [
    "X_complete = interpolate_nans(X_incomplete)\n",
    "print X_complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "meta = ['name', 'reporting']\n",
    "good = ['active_days', 'number_of_contacts', 'duration',\n",
    "        'percent_initiated_conversations', 'percent_initiated_interactions', \n",
    "        'response_delay_text', 'response_rate_text', 'entropy_of_contacts', \n",
    "        'interevent_time', 'percent_pareto_interactions', 'percent_pareto_durations', \n",
    "        'percent_interactions_out', 'percent_concluded_conversations', 'percent_overlap_conversations']\n",
    "maybe = ['balance_of_contacts', 'number_of_interactions']\n",
    "work = ['percent_nocturnal']\n",
    "drop = ['interactions_per_contact']\n",
    "\n",
    "for ex in meta:# + good + work + drop + maybe:\n",
    "    del indicators_d[ex]\n",
    "\n",
    "indicators_flat = bc_d.utils.flatten(indicators_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9000 9001 9002]\n",
      " [9010 9011 9012]\n",
      " [9020 9021 9022]]\n",
      "[[9100 9101 9102]\n",
      " [9110 9111 9112]\n",
      " [9120 9121 9122]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[9000, 9001, 9002], [9010, 9011, 9012], [9020, 9021, 9022]], np.int32)\n",
    "y = np.array([[9100, 9101, 9102], [9110, 9111, 9112], [9120, 9121, 9122]], np.int32)\n",
    "print x\n",
    "print y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[9000 9100]\n",
      "  [9001 9101]\n",
      "  [9002 9102]]\n",
      "\n",
      " [[9010 9110]\n",
      "  [9011 9111]\n",
      "  [9012 9112]]\n",
      "\n",
      " [[9020 9120]\n",
      "  [9021 9121]\n",
      "  [9022 9122]]]\n"
     ]
    }
   ],
   "source": [
    "Z = np.dstack((x,y))\n",
    "print Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9110"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z[1,0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
